import gymnasium as gym
import numpy as np
import matplotlib.pyplot as plt
from auction import auction_algorithm  

class TEWAEnv(gym.Env):
    """
    TEWA Environment where RL evaluates threats and the Auction Algorithm handles assignments.
    """

    def __init__(self, num_threats=5, num_weapons=2, battlefield_size=100, missiles_per_weapon=2):
        super(TEWAEnv, self).__init__()

        self.num_threats = num_threats
        self.num_weapons = num_weapons
        self.missiles_per_weapon = missiles_per_weapon
        self.battlefield_size = battlefield_size

        # New Observation Space (Only Threat Features)
        # Format: [severity, distance, heading_diff, speed] for each threat
        self.observation_space = gym.spaces.Box(
            low=0, high=100, shape=(num_threats, 4), dtype=np.float32
        )

        # New Action Space (Threat Prioritization)
        # RL outputs a ranking of threats 
        self.action_space = gym.spaces.MultiDiscrete([num_threats])

        self.reset()

    def reset(self, seed=None, options=None):
        """
        Resets the environment with random threats and missile status.
        Now using dynamic observations instead of fixed padding.
        """
        np.random.seed(seed)

        # ðŸ”¥ Initialize dynamic threats
        self.threats = np.column_stack((
            np.random.uniform(10, self.battlefield_size - 10, self.num_threats),
            np.random.uniform(10, self.battlefield_size - 10, self.num_threats),
            np.random.uniform(1, 5, self.num_threats),
            np.random.uniform(0, 360, self.num_threats),
            np.random.uniform(0.5, 1, self.num_threats)
        ))

        # ðŸ”¥ Initialize dynamic weapons
        weapon_x_positions = np.linspace(10, self.battlefield_size - 10, self.num_weapons)
        weapon_y_positions = np.full(self.num_weapons, self.battlefield_size / 2)
        self.weapons = np.column_stack((weapon_x_positions, weapon_y_positions, np.full(self.num_weapons, self.missiles_per_weapon)))

        # Reset tracking variables
        self.steps = 0
        self.weapon_assignment_duration = {}  # Track how long each weapon assigns to each threat
        self.previous_weapon_assignment = {}  # Track previous assignments
        self.tracked_assignments = []  # Store active assignments
        self.assignment_duration = {i: 0 for i in range(self.num_threats)}  # Track time assigned per threat

        # **Dynamic observation generation**
        self.state = self.get_observation()

        return self.state.astype(np.float32), {}


    def _get_observation(self):
        """
        Returns the observation containing only relevant threat features.
        Format: [severity, distance, heading_diff, speed] for each threat.
        """
        base_x, base_y = self.battlefield_size / 2, self.battlefield_size / 2
        observation = []

        for i in range(self.num_threats):
            threat_x, threat_y, speed, orientation, severity = self.threats[i]

            # Distance to base
            distance = np.linalg.norm([base_x - threat_x, base_y - threat_y])

            # Heading difference
            heading_to_base = np.degrees(np.arctan2(base_y - threat_y, base_x - threat_x))
            heading_diff = min(abs(heading_to_base - orientation), 360 - abs(heading_to_base - orientation))

            # Normalize features (0-100 scale)
            distance = np.clip((100 - distance) / 100 * 100, 0, 100)
            heading_diff = np.clip((180 - heading_diff) / 180 * 100, 0, 100)
            speed = np.clip(speed / 5 * 100, 0, 100)

            observation.append([severity, distance, heading_diff, speed])

        return np.array(observation, dtype=np.float32)

    def step(self, action):
        
        self.steps += 1
        reward = 0
        done = False
        # âœ… Get threat evaluation from RL (agent prioritizes threats)
        threat_priority = np.argsort(action)  # Sort by RL's learned threat priority
        threat_ranking = {threat_id: rank for rank, threat_id in enumerate(threat_priority)}

        # âœ… Convert action into (num_weapons Ã— missiles_per_weapon) matrix
        action = np.array(action).reshape(self.num_weapons, self.missiles_per_weapon)


        # ðŸ”¥ Track assigned threats dynamically
        assigned_this_step = {}
        self.tracked_assignments = []
        threat_assignments = {i: 0 for i in range(self.num_threats)}


        for weapon_idx in range(self.num_weapons):
            for missile_idx in range(self.missiles_per_weapon):
                if self.weapons[weapon_idx, 2] > 0:
                    threat_idx = action[weapon_idx, missile_idx]

                    if 0 <= threat_idx < self.num_threats:
                        assigned_this_step[threat_idx] = weapon_idx
                        self.tracked_assignments.append((weapon_idx, threat_idx))
                        threat_assignments[threat_idx] += 1
                        self.weapons[weapon_idx, 2] -= 1  # Reduce missile count
                        # âœ… **Reward for prioritizing high-risk threats**
                        danger_rank = threat_ranking.get(threat_idx, len(threat_priority))
                        max_rank = len(threat_priority)
                        reward += (max_rank - danger_rank) * 2  # Higher rank gets more reward

                        # âœ… **Track assignment duration (stability bonus)**
                        if self.previous_weapon_assignment.get(threat_idx) == weapon_idx:
                            self.weapon_assignment_duration[(weapon_idx, threat_idx)] = self.weapon_assignment_duration.get((weapon_idx, threat_idx), 0) + 1
                        else:
                            self.weapon_assignment_duration[(weapon_idx, threat_idx)] = 1  # Reset duration if reassigned
        
        # âœ… **Penalty for leaving high-risk threats unassigned**
        for threat_idx in range(self.num_threats):
            if threat_idx not in assigned_this_step:
                low_priority_penalty = (threat_ranking.get(threat_idx, len(threat_priority)) / len(threat_priority)) * -1
                reward += low_priority_penalty

        # âœ… **Apply stability reward**
        stability_reward = sum(1 for t, w in assigned_this_step.items() if self.previous_weapon_assignment.get(t) == w)
        reward += stability_reward * 0.5 
     

        # ðŸ”¥ Remove threats assigned for too long
        threats_to_remove = [tid for tid, duration in self.assignment_duration.items() if duration >= 3]
        threats_to_remove = [tid for tid in threats_to_remove if tid < self.num_threats] 

        if threats_to_remove:
            self.threats = np.delete(self.threats, threats_to_remove, axis=0)
            self.num_threats = len(self.threats)
            reward += len(threats_to_remove) * 10
            # Remove eliminated threats from tracking
            self.weapon_assignment_duration = {(w, t): d for (w, t), d in self.weapon_assignment_duration.items() if t not in threats_to_remove}

        # ðŸ”¥ Dynamic Threat Movement
        for i in range(self.num_threats):
            angle_rad = np.radians(self.threats[i, 3])
            self.threats[i, 0] += self.threats[i, 2] * np.cos(angle_rad)
            self.threats[i, 1] += self.threats[i, 2] * np.sin(angle_rad)
            self.threats[i, 0] = np.clip(self.threats[i, 0], 0, self.battlefield_size)
            self.threats[i, 1] = np.clip(self.threats[i, 1], 0, self.battlefield_size)
        
        # âœ… **Penalize threats getting too close to weapons**
        for weapon in self.weapons:
            for threat in self.threats:
                distance = np.linalg.norm(threat[:2] - weapon[:2])
                if distance < 10:  # If a threat gets too close, penalize
                    reward -= 5

        # ðŸ”¥ If all threats are eliminated, end episode
        if self.num_threats == 0:
            reward += 50
            done = True
        if self.steps >= 500:
            reward -= 10
            done = True
            
        # ðŸ”¥ Dynamically concatenate new observation without padding
        self.state = self.get_observation()

        # âœ… **Debug information**
        print(f"\n[Step {self.steps}] Active Threats: {self.num_threats}")
        for (weapon, threat), duration in self.weapon_assignment_duration.items():
            print(f"Weapon {weapon} â†’ Threat {threat} assigned for {duration} steps")
        print(f"Reward: {reward}")


        return self.state.astype(np.float32), reward, done, False, {}


    def render(self, action=None):
        
        plt.clf()
        plt.xlim(0, self.battlefield_size)
        plt.ylim(0, self.battlefield_size)
        plt.grid(True)

        # ðŸ”¥ Plot threats with movement vectors (arrows)
        for i in range(self.num_threats):
            plt.scatter(self.threats[i, 0], self.threats[i, 1], color='red', s=100)
            plt.text(self.threats[i, 0] + 2, self.threats[i, 1] + 2, f"T{i}", fontsize=10, color='black')

            # Draw movement direction
            plt.arrow(self.threats[i, 0], self.threats[i, 1], 
                    np.cos(np.radians(self.threats[i, 3])) * 5, 
                    np.sin(np.radians(self.threats[i, 3])) * 5, 
                    head_width=2, fc='black')

        # ðŸ”¥ Plot weapons at separate locations
        for i in range(self.num_weapons):
            plt.scatter(self.weapons[i, 0], self.weapons[i, 1], color='green', s=150)
            plt.text(self.weapons[i, 0] + 2, self.weapons[i, 1] + 2, f"W{i}", fontsize=10, color='black')

        # ðŸ”¥ If we have an action, get assignments from Auction Algorithm
        if action is not None:
            reward_matrix = np.zeros((self.num_weapons, self.num_threats))
            for rank, threat_idx in enumerate(action):
                if threat_idx < self.num_threats:
                    reward_matrix[:, threat_idx] = (self.num_threats - rank) * 10  # Higher-ranked threats get higher values

            assignments = auction_algorithm(reward_matrix)  # ðŸ”¥ Assign threats using the auction algorithm

            # ðŸ”¥ Draw assignment lines
            for weapon_idx, threat_idx in assignments.items():
                if 0 <= threat_idx < len(self.threats):
                    plt.plot([self.weapons[weapon_idx, 0], self.threats[threat_idx, 0]],
                            [self.weapons[weapon_idx, 1], self.threats[threat_idx, 1]], 'k--', linewidth=1)
        
        plt.title(f"Battlefield at Step {self.steps}")
        plt.pause(0.6)

        # ðŸ”´ **Print the Threat Evaluation List**
        print("\nðŸ”´ **Threat Evaluation List (Most Dangerous First)** ðŸ”´")
        print(f"{'Rank':<5} {'Threat ID':<10} {'Danger Score':<15} {'Distance':<10} {'Heading':<15} {'Severity':<10} {'Speed':<5}")
        print("-" * 80)
        
        for rank, (tid, danger_score, distance_score, heading_score, severity_score, speed_score) in enumerate(self.evaluate_threats()):
            print(f"{rank+1:<5} {tid:<10} {danger_score:<15.2f} {distance_score:<10.2f} {heading_score:<15.2f} {severity_score:<10.2f} {speed_score:<5.2f}")
